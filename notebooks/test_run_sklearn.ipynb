{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b515428-ba1b-42c8-8627-22aed51c7b70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10c0da430>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../neat\"))\n",
    "\n",
    "from cppn import *\n",
    "from genome import *\n",
    "from speciation import *\n",
    "\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "374d77b6-0c6c-4e60-8dc1-51620ed59993",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "digits = load_digits()\n",
    "\n",
    "data_tensor = torch.tensor(digits.data, dtype=torch.float32)\n",
    "data_tensor = torch.tensor(digits.data / 16.0, dtype=torch.float32) # Normalize for neat\n",
    "target_tensor = torch.tensor(digits.target, dtype=torch.long)\n",
    "\n",
    "# 80/20 split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data_tensor, target_tensor, test_size=0.2, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "# Batch is the full size because there is no backpropogation\n",
    "train_loader = DataLoader(train_dataset, batch_size=len(train_dataset))\n",
    "test_loader = DataLoader(test_dataset, batch_size=len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad9c2898-ce4a-48dc-ac84-29635deaa2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init stuff\n",
    "\n",
    "# Hyperparameters\n",
    "population_size = 200\n",
    "epochs = 300\n",
    "input_dim = 8*8\n",
    "output_dim = 10\n",
    "top_k = 0.3 # The percentage of genomes to keep for reproduction\n",
    "crossover_percent = 0.5\n",
    "\n",
    "# hyperparameters for measuring compatibility from https://nn.cs.utexas.edu/downloads/papers/stanley.cec02.pdf\n",
    "c1 = 1.0\n",
    "c2 = 1.0\n",
    "c3 = 3.0\n",
    "delta_thresh = 3.4\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Using list of lists\n",
    "# Dead species will not be kept track of. There will be no empty list\n",
    "population = []\n",
    "\n",
    "# Reset NN Class\n",
    "reset_NN_class_state()\n",
    "\n",
    "# Init first model\n",
    "new_model = {\"model\": NN(input_dim, output_dim).to(device), \"loss\": float('inf'), \"fitness\": -float('inf')}\n",
    "population.append([new_model])\n",
    "\n",
    "for _ in range(population_size - 1):\n",
    "    new_model = {\"model\": NN(input_dim, output_dim).to(device), \"loss\": float('inf'), \"fitness\": -float('inf')}\n",
    "    \n",
    "    added = False\n",
    "    for idx, species in enumerate(population):\n",
    "        delta = measure_compatibility(new_model['model'], species[0]['model'], c1, c2, c3)\n",
    "\n",
    "        if delta < delta_thresh:\n",
    "            population[idx].append(new_model)\n",
    "            added = True\n",
    "            break\n",
    "    if not added:\n",
    "        # New species created\n",
    "        population.append([new_model])\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc3cc81f-5ae0-40ea-8172-2e1bad45c4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8af7ad22-51ec-4a2d-8105-a54cd274077b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "top model loss: 4.39\n",
      "10\n",
      "epoch: 1\n",
      "top model loss: 3.95\n",
      "11\n",
      "epoch: 2\n",
      "top model loss: 3.74\n",
      "4\n",
      "epoch: 3\n",
      "top model loss: 3.43\n",
      "5\n",
      "epoch: 4\n",
      "top model loss: 3.13\n",
      "5\n",
      "epoch: 5\n",
      "top model loss: 3.13\n",
      "4\n",
      "epoch: 6\n",
      "top model loss: 3.04\n",
      "2\n",
      "epoch: 7\n",
      "top model loss: 3.04\n",
      "3\n",
      "epoch: 8\n",
      "top model loss: 3.04\n",
      "2\n",
      "epoch: 9\n",
      "top model loss: 2.89\n",
      "2\n",
      "epoch: 10\n",
      "top model loss: 2.61\n",
      "2\n",
      "epoch: 11\n",
      "top model loss: 2.54\n",
      "1\n",
      "epoch: 12\n",
      "top model loss: 2.29\n",
      "1\n",
      "epoch: 13\n",
      "top model loss: 2.23\n",
      "1\n",
      "epoch: 14\n",
      "top model loss: 2.23\n",
      "1\n",
      "epoch: 15\n",
      "top model loss: 2.17\n",
      "1\n",
      "epoch: 16\n",
      "top model loss: 2.07\n",
      "1\n",
      "epoch: 17\n",
      "top model loss: 1.91\n",
      "1\n",
      "epoch: 18\n",
      "top model loss: 1.91\n",
      "1\n",
      "epoch: 19\n",
      "top model loss: 1.83\n",
      "1\n",
      "epoch: 20\n",
      "top model loss: 1.70\n",
      "1\n",
      "epoch: 21\n",
      "top model loss: 1.70\n",
      "1\n",
      "epoch: 22\n",
      "top model loss: 1.66\n",
      "1\n",
      "epoch: 23\n",
      "top model loss: 1.65\n",
      "1\n",
      "epoch: 24\n",
      "top model loss: 1.64\n",
      "1\n",
      "epoch: 25\n",
      "top model loss: 1.48\n",
      "1\n",
      "epoch: 26\n",
      "top model loss: 1.53\n",
      "1\n",
      "epoch: 27\n",
      "top model loss: 1.44\n",
      "1\n",
      "epoch: 28\n",
      "top model loss: 1.48\n",
      "1\n",
      "epoch: 29\n",
      "top model loss: 1.47\n",
      "1\n",
      "epoch: 30\n",
      "top model loss: 1.46\n",
      "1\n",
      "epoch: 31\n",
      "top model loss: 1.43\n",
      "1\n",
      "epoch: 32\n",
      "top model loss: 1.41\n",
      "1\n",
      "epoch: 33\n",
      "top model loss: 1.32\n",
      "1\n",
      "epoch: 34\n",
      "top model loss: 1.31\n",
      "1\n",
      "epoch: 35\n",
      "top model loss: 1.21\n",
      "1\n",
      "epoch: 36\n",
      "top model loss: 1.21\n",
      "1\n",
      "epoch: 37\n",
      "top model loss: 1.21\n",
      "1\n",
      "epoch: 38\n",
      "top model loss: 1.21\n",
      "1\n",
      "epoch: 39\n",
      "top model loss: 1.18\n",
      "1\n",
      "epoch: 40\n",
      "top model loss: 1.14\n",
      "1\n",
      "epoch: 41\n",
      "top model loss: 1.12\n",
      "1\n",
      "epoch: 42\n",
      "top model loss: 1.12\n",
      "1\n",
      "epoch: 43\n",
      "top model loss: 1.11\n",
      "1\n",
      "epoch: 44\n",
      "top model loss: 1.07\n",
      "1\n",
      "epoch: 45\n",
      "top model loss: 1.08\n",
      "1\n",
      "epoch: 46\n",
      "top model loss: 1.06\n",
      "1\n",
      "epoch: 47\n",
      "top model loss: 1.04\n",
      "1\n",
      "epoch: 48\n",
      "top model loss: 1.01\n",
      "1\n",
      "epoch: 49\n",
      "top model loss: 1.00\n",
      "1\n",
      "epoch: 50\n",
      "top model loss: 1.00\n",
      "1\n",
      "epoch: 51\n",
      "top model loss: 0.99\n",
      "1\n",
      "epoch: 52\n",
      "top model loss: 0.98\n",
      "1\n",
      "epoch: 53\n",
      "top model loss: 0.97\n",
      "1\n",
      "epoch: 54\n",
      "top model loss: 0.93\n",
      "1\n",
      "epoch: 55\n",
      "top model loss: 0.93\n",
      "1\n",
      "epoch: 56\n",
      "top model loss: 0.92\n",
      "1\n",
      "epoch: 57\n",
      "top model loss: 0.92\n",
      "1\n",
      "epoch: 58\n",
      "top model loss: 0.90\n",
      "1\n",
      "epoch: 59\n",
      "top model loss: 0.90\n",
      "1\n",
      "epoch: 60\n",
      "top model loss: 0.88\n",
      "1\n",
      "epoch: 61\n",
      "top model loss: 0.87\n",
      "1\n",
      "epoch: 62\n",
      "top model loss: 0.87\n",
      "1\n",
      "epoch: 63\n",
      "top model loss: 0.86\n",
      "1\n",
      "epoch: 64\n",
      "top model loss: 0.86\n",
      "1\n",
      "epoch: 65\n",
      "top model loss: 0.85\n",
      "1\n",
      "epoch: 66\n",
      "top model loss: 0.84\n",
      "1\n",
      "epoch: 67\n",
      "top model loss: 0.83\n",
      "1\n",
      "epoch: 68\n",
      "top model loss: 0.82\n",
      "1\n",
      "epoch: 69\n",
      "top model loss: 0.79\n",
      "1\n",
      "epoch: 70\n",
      "top model loss: 0.80\n",
      "1\n",
      "epoch: 71\n",
      "top model loss: 0.78\n",
      "1\n",
      "epoch: 72\n",
      "top model loss: 0.77\n",
      "1\n",
      "epoch: 73\n",
      "top model loss: 0.77\n",
      "1\n",
      "epoch: 74\n",
      "top model loss: 0.76\n",
      "1\n",
      "epoch: 75\n",
      "top model loss: 0.75\n",
      "1\n",
      "epoch: 76\n",
      "top model loss: 0.75\n",
      "1\n",
      "epoch: 77\n",
      "top model loss: 0.74\n",
      "1\n",
      "epoch: 78\n",
      "top model loss: 0.73\n",
      "1\n",
      "epoch: 79\n",
      "top model loss: 0.73\n",
      "1\n",
      "epoch: 80\n",
      "top model loss: 0.72\n",
      "1\n",
      "epoch: 81\n",
      "top model loss: 0.72\n",
      "1\n",
      "epoch: 82\n",
      "top model loss: 0.72\n",
      "1\n",
      "epoch: 83\n",
      "top model loss: 0.71\n",
      "1\n",
      "epoch: 84\n",
      "top model loss: 0.70\n",
      "1\n",
      "epoch: 85\n",
      "top model loss: 0.70\n",
      "1\n",
      "epoch: 86\n",
      "top model loss: 0.69\n",
      "1\n",
      "epoch: 87\n",
      "top model loss: 0.68\n",
      "1\n",
      "epoch: 88\n",
      "top model loss: 0.68\n",
      "1\n",
      "epoch: 89\n",
      "top model loss: 0.68\n",
      "1\n",
      "epoch: 90\n",
      "top model loss: 0.67\n",
      "1\n",
      "epoch: 91\n",
      "top model loss: 0.67\n",
      "1\n",
      "epoch: 92\n",
      "top model loss: 0.66\n",
      "1\n",
      "epoch: 93\n",
      "top model loss: 0.66\n",
      "1\n",
      "epoch: 94\n",
      "top model loss: 0.65\n",
      "1\n",
      "epoch: 95\n",
      "top model loss: 0.64\n",
      "1\n",
      "epoch: 96\n",
      "top model loss: 0.63\n",
      "1\n",
      "epoch: 97\n",
      "top model loss: 0.63\n",
      "1\n",
      "epoch: 98\n",
      "top model loss: 0.62\n",
      "1\n",
      "epoch: 99\n",
      "top model loss: 0.62\n",
      "1\n",
      "epoch: 100\n",
      "top model loss: 0.61\n",
      "1\n",
      "epoch: 101\n",
      "top model loss: 0.61\n",
      "1\n",
      "epoch: 102\n",
      "top model loss: 0.61\n",
      "1\n",
      "epoch: 103\n",
      "top model loss: 0.61\n",
      "1\n",
      "epoch: 104\n",
      "top model loss: 0.60\n",
      "1\n",
      "epoch: 105\n",
      "top model loss: 0.59\n",
      "1\n",
      "epoch: 106\n",
      "top model loss: 0.58\n",
      "1\n",
      "epoch: 107\n",
      "top model loss: 0.57\n",
      "1\n",
      "epoch: 108\n",
      "top model loss: 0.57\n",
      "1\n",
      "epoch: 109\n",
      "top model loss: 0.57\n",
      "1\n",
      "epoch: 110\n",
      "top model loss: 0.56\n",
      "1\n",
      "epoch: 111\n",
      "top model loss: 0.56\n",
      "1\n",
      "epoch: 112\n",
      "top model loss: 0.55\n",
      "1\n",
      "epoch: 113\n",
      "top model loss: 0.55\n",
      "1\n",
      "epoch: 114\n",
      "top model loss: 0.54\n",
      "1\n",
      "epoch: 115\n",
      "top model loss: 0.54\n",
      "1\n",
      "epoch: 116\n",
      "top model loss: 0.53\n",
      "1\n",
      "epoch: 117\n",
      "top model loss: 0.53\n",
      "1\n",
      "epoch: 118\n",
      "top model loss: 0.52\n",
      "1\n",
      "epoch: 119\n",
      "top model loss: 0.53\n",
      "1\n",
      "epoch: 120\n",
      "top model loss: 0.52\n",
      "1\n",
      "epoch: 121\n",
      "top model loss: 0.52\n",
      "1\n",
      "epoch: 122\n",
      "top model loss: 0.52\n",
      "1\n",
      "epoch: 123\n",
      "top model loss: 0.52\n",
      "1\n",
      "epoch: 124\n",
      "top model loss: 0.51\n",
      "1\n",
      "epoch: 125\n",
      "top model loss: 0.51\n",
      "1\n",
      "epoch: 126\n",
      "top model loss: 0.51\n",
      "1\n",
      "epoch: 127\n",
      "top model loss: 0.50\n",
      "1\n",
      "epoch: 128\n",
      "top model loss: 0.50\n",
      "1\n",
      "epoch: 129\n",
      "top model loss: 0.50\n",
      "1\n",
      "epoch: 130\n",
      "top model loss: 0.49\n",
      "1\n",
      "epoch: 131\n",
      "top model loss: 0.49\n",
      "1\n",
      "epoch: 132\n",
      "top model loss: 0.49\n",
      "1\n",
      "epoch: 133\n",
      "top model loss: 0.48\n",
      "1\n",
      "epoch: 134\n",
      "top model loss: 0.48\n",
      "1\n",
      "epoch: 135\n",
      "top model loss: 0.48\n",
      "1\n",
      "epoch: 136\n",
      "top model loss: 0.48\n",
      "1\n",
      "epoch: 137\n",
      "top model loss: 0.47\n",
      "1\n",
      "epoch: 138\n",
      "top model loss: 0.47\n",
      "1\n",
      "epoch: 139\n",
      "top model loss: 0.47\n",
      "1\n",
      "epoch: 140\n",
      "top model loss: 0.46\n",
      "1\n",
      "epoch: 141\n",
      "top model loss: 0.46\n",
      "1\n",
      "epoch: 142\n",
      "top model loss: 0.46\n",
      "1\n",
      "epoch: 143\n",
      "top model loss: 0.46\n",
      "1\n",
      "epoch: 144\n",
      "top model loss: 0.45\n",
      "1\n",
      "epoch: 145\n",
      "top model loss: 0.45\n",
      "1\n",
      "epoch: 146\n",
      "top model loss: 0.45\n",
      "1\n",
      "epoch: 147\n",
      "top model loss: 0.44\n",
      "1\n",
      "epoch: 148\n",
      "top model loss: 0.44\n",
      "1\n",
      "epoch: 149\n",
      "top model loss: 0.44\n",
      "1\n",
      "epoch: 150\n",
      "top model loss: 0.43\n",
      "1\n",
      "epoch: 151\n",
      "top model loss: 0.43\n",
      "1\n",
      "epoch: 152\n",
      "top model loss: 0.43\n",
      "1\n",
      "epoch: 153\n",
      "top model loss: 0.42\n",
      "1\n",
      "epoch: 154\n",
      "top model loss: 0.42\n",
      "1\n",
      "epoch: 155\n",
      "top model loss: 0.42\n",
      "1\n",
      "epoch: 156\n",
      "top model loss: 0.42\n",
      "1\n",
      "epoch: 157\n",
      "top model loss: 0.42\n",
      "1\n",
      "epoch: 158\n",
      "top model loss: 0.41\n",
      "1\n",
      "epoch: 159\n",
      "top model loss: 0.41\n",
      "1\n",
      "epoch: 160\n",
      "top model loss: 0.41\n",
      "1\n",
      "epoch: 161\n",
      "top model loss: 0.41\n",
      "1\n",
      "epoch: 162\n",
      "top model loss: 0.40\n",
      "1\n",
      "epoch: 163\n",
      "top model loss: 0.40\n",
      "1\n",
      "epoch: 164\n",
      "top model loss: 0.40\n",
      "1\n",
      "epoch: 165\n",
      "top model loss: 0.40\n",
      "1\n",
      "epoch: 166\n",
      "top model loss: 0.39\n",
      "1\n",
      "epoch: 167\n",
      "top model loss: 0.39\n",
      "1\n",
      "epoch: 168\n",
      "top model loss: 0.39\n",
      "1\n",
      "epoch: 169\n",
      "top model loss: 0.39\n",
      "1\n",
      "epoch: 170\n",
      "top model loss: 0.39\n",
      "1\n",
      "epoch: 171\n",
      "top model loss: 0.38\n",
      "1\n",
      "epoch: 172\n",
      "top model loss: 0.38\n",
      "1\n",
      "epoch: 173\n",
      "top model loss: 0.38\n",
      "1\n",
      "epoch: 174\n",
      "top model loss: 0.38\n",
      "1\n",
      "epoch: 175\n",
      "top model loss: 0.37\n",
      "1\n",
      "epoch: 176\n",
      "top model loss: 0.37\n",
      "1\n",
      "epoch: 177\n",
      "top model loss: 0.37\n",
      "1\n",
      "epoch: 178\n",
      "top model loss: 0.37\n",
      "1\n",
      "epoch: 179\n",
      "top model loss: 0.37\n",
      "1\n",
      "epoch: 180\n",
      "top model loss: 0.37\n",
      "1\n",
      "epoch: 181\n",
      "top model loss: 0.37\n",
      "1\n",
      "epoch: 182\n",
      "top model loss: 0.36\n",
      "1\n",
      "epoch: 183\n",
      "top model loss: 0.36\n",
      "1\n",
      "epoch: 184\n",
      "top model loss: 0.36\n",
      "1\n",
      "epoch: 185\n",
      "top model loss: 0.36\n",
      "1\n",
      "epoch: 186\n",
      "top model loss: 0.36\n",
      "1\n",
      "epoch: 187\n",
      "top model loss: 0.36\n",
      "1\n",
      "epoch: 188\n",
      "top model loss: 0.35\n",
      "1\n",
      "epoch: 189\n",
      "top model loss: 0.35\n",
      "1\n",
      "epoch: 190\n",
      "top model loss: 0.35\n",
      "1\n",
      "epoch: 191\n",
      "top model loss: 0.35\n",
      "1\n",
      "epoch: 192\n",
      "top model loss: 0.35\n",
      "1\n",
      "epoch: 193\n",
      "top model loss: 0.35\n",
      "1\n",
      "epoch: 194\n",
      "top model loss: 0.34\n",
      "1\n",
      "epoch: 195\n",
      "top model loss: 0.34\n",
      "1\n",
      "epoch: 196\n",
      "top model loss: 0.34\n",
      "1\n",
      "epoch: 197\n",
      "top model loss: 0.34\n",
      "1\n",
      "epoch: 198\n",
      "top model loss: 0.34\n",
      "1\n",
      "epoch: 199\n",
      "top model loss: 0.34\n",
      "1\n",
      "epoch: 200\n",
      "top model loss: 0.34\n",
      "1\n",
      "epoch: 201\n",
      "top model loss: 0.33\n",
      "1\n",
      "epoch: 202\n",
      "top model loss: 0.33\n",
      "1\n",
      "epoch: 203\n",
      "top model loss: 0.33\n",
      "1\n",
      "epoch: 204\n",
      "top model loss: 0.33\n",
      "1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     15\u001b[39m data_batch = data_batch.to(device)\n\u001b[32m     16\u001b[39m label_batch = label_batch.to(device)\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m output = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m loss = loss_fn(output, label_batch)\n\u001b[32m     20\u001b[39m total_loss += loss.item() * data_batch.size(\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/neat/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/neat/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/neat/neat/cppn.py:183\u001b[39m, in \u001b[36mNN.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    179\u001b[39m out_node.received += \u001b[32m1\u001b[39m\n\u001b[32m    181\u001b[39m \u001b[38;5;66;03m# Only enqueue if all inputs are received\u001b[39;00m\n\u001b[32m    182\u001b[39m \u001b[38;5;66;03m# Note: vectorized check â€” adds node to queue if all samples are ready\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43m(\u001b[49m\u001b[43mout_node\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreceived\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_node\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnum_incoming_connections\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    184\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m out_node.is_output:\n\u001b[32m    185\u001b[39m         out_node.val = torch.sigmoid(out_node.val)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# \"Training\" loop\n",
    "\n",
    "for epoch in range(epochs):  \n",
    "    for species in population:\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for model_info in species:\n",
    "\n",
    "                model_info[\"model\"] = model_info[\"model\"].to(device)\n",
    "                model = model_info[\"model\"]\n",
    "                total_loss = 0.0\n",
    "                total_samples = 0\n",
    "    \n",
    "                for data_batch, label_batch in train_loader:\n",
    "                    data_batch = data_batch.to(device)\n",
    "                    label_batch = label_batch.to(device)\n",
    "\n",
    "                    output = model(data_batch)\n",
    "                    loss = loss_fn(output, label_batch)\n",
    "                    total_loss += loss.item() * data_batch.size(0)\n",
    "                    total_samples += data_batch.size(0)\n",
    "                \n",
    "                model_info[\"loss\"] = total_loss / total_samples\n",
    "    flattened_population = []\n",
    "\n",
    "    for species in population:\n",
    "        for genome in species:\n",
    "            flattened_population.append(genome)\n",
    "            \n",
    "    ranked_models = sorted([model_info for model_info in flattened_population], key=lambda x: x[\"loss\"])\n",
    "    lowest_loss = ranked_models[0]['loss']\n",
    "\n",
    "    # Fitness sharing\n",
    "    for species in population:\n",
    "        species_size = len(species)\n",
    "        for genome in species:\n",
    "            raw_fitness = 1 / (1 + genome['loss'])\n",
    "            genome['fitness'] = raw_fitness / species_size\n",
    "\n",
    "    # Last epoch do not make new models\n",
    "    if epoch == epochs - 1:\n",
    "        break\n",
    "\n",
    "    # This is just a list not a list of lists\n",
    "    new_population = []\n",
    "\n",
    "    for species in population:\n",
    "        offspring = []\n",
    "\n",
    "        ranked_models = sorted([model_info for model_info in species], key=lambda x: x[\"fitness\"], reverse=True)\n",
    "        parents = [model_info for model_info in ranked_models[:math.ceil(top_k * len(ranked_models))]]\n",
    "\n",
    "        for i in range(math.ceil(crossover_percent * len(ranked_models))):\n",
    "            p1 = random.choice(parents)\n",
    "            p2 = random.choice(parents)\n",
    "            child = crossover(p1, p2)\n",
    "            offspring.append({\"model\": child.to(device), \"loss\": float('inf'), \"fitness\": -float('inf')})\n",
    "    \n",
    "        while len(offspring) != len(ranked_models):\n",
    "            offspring.append({\"model\": random.choice(parents)['model'].mutate(True).to(device), \"loss\": float('inf'), \"fitness\": -float('inf')})\n",
    "            \n",
    "        new_population.extend(offspring)\n",
    "\n",
    "    # Redivide into species\n",
    "    new_population_divided = []\n",
    "\n",
    "    for model in new_population:    \n",
    "        # First model\n",
    "        if len(new_population_divided) == 0:\n",
    "            new_population_divided.append([model])\n",
    "        else:\n",
    "            added = False\n",
    "            for idx, species in enumerate(new_population_divided):\n",
    "                delta = measure_compatibility(model['model'], species[0]['model'], c1, c2, c3)\n",
    "\n",
    "                if delta < delta_thresh:\n",
    "                    new_population_divided[idx].append(model)\n",
    "                    added = True\n",
    "                    break\n",
    "            if not added:\n",
    "                # New species created\n",
    "                new_population_divided.append([model])\n",
    "                    \n",
    "    population = new_population_divided\n",
    "\n",
    "    # To keep track of the num of species per epoch\n",
    "    print(f\"epoch: {epoch}\")\n",
    "    print(f\"top model loss: {lowest_loss:.2f}\")\n",
    "    print(len(population))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64cecfec-8bdb-4aff-9290-5ce6a54a49c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.33%\n"
     ]
    }
   ],
   "source": [
    "# Evaulate\n",
    "model = ranked_models[0]['model'].to(device)\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, labels in test_loader:\n",
    "        data = data.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(data)  # logits\n",
    "        predicted = torch.argmax(outputs, dim=1)  # class indices\n",
    "\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dee5161e-3d9e-48e8-828c-b18612a14f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"../models/sklearn_digits_300pop_300epoch{{accuracy * 100:.2f}}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a33a8bf-21bb-4894-a142-1af85d5556ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neat",
   "language": "python",
   "name": "neat"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
