{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36d7f272-efa7-4178-b3ad-a998ed0beddc",
   "metadata": {},
   "source": [
    "FGSM on a simple fnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b4a3e2e-0c17-4b79-bfb3-f01690c35b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ef0358e-d2fc-4268-bb94-603ed55c71e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "digits = load_digits()\n",
    "\n",
    "data_tensor = torch.tensor(digits.data, dtype=torch.float32)\n",
    "data_tensor = torch.tensor(digits.data / 16.0, dtype=torch.float32) # Normalize for neat\n",
    "target_tensor = torch.tensor(digits.target, dtype=torch.long)\n",
    "\n",
    "# 80/20 split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data_tensor, target_tensor, test_size=0.2, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "# Batch is the full size because there is no backpropogation\n",
    "train_loader = DataLoader(train_dataset, batch_size=len(train_dataset))\n",
    "test_loader = DataLoader(test_dataset, batch_size=len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af748ab8-48f4-4e29-a5ab-f5b5a2d7ab3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1437"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "488f3861-4346-40a4-8538-3c6e41c555cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple FFN approach\n",
    "\n",
    "class FFN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(8*8, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "        return F.softmax(logits, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64f8daa1-cd32-4c01-beb2-e35895789f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.31947660446167\n",
      "2.256021499633789\n",
      "2.192096471786499\n",
      "2.1132774353027344\n",
      "2.019395351409912\n",
      "1.911458969116211\n",
      "1.7906699180603027\n",
      "1.6591330766677856\n",
      "1.5204237699508667\n",
      "1.3793058395385742\n",
      "1.2411341667175293\n",
      "1.1108441352844238\n",
      "0.9920622706413269\n",
      "0.8865486979484558\n",
      "0.794504702091217\n",
      "0.7150220274925232\n",
      "0.6466823220252991\n",
      "0.5879400372505188\n",
      "0.5373164415359497\n",
      "0.4935389757156372\n",
      "0.455515593290329\n",
      "0.42232492566108704\n",
      "0.39320099353790283\n",
      "0.36750519275665283\n",
      "0.3447161912918091\n",
      "0.3243710398674011\n",
      "0.3061259984970093\n",
      "0.2897055745124817\n",
      "0.27488818764686584\n",
      "0.26146233081817627\n",
      "0.24922321736812592\n",
      "0.23801802098751068\n",
      "0.2277299016714096\n",
      "0.21825653314590454\n",
      "0.2095002382993698\n",
      "0.2013828456401825\n",
      "0.1938292682170868\n",
      "0.18677860498428345\n",
      "0.18016952276229858\n",
      "0.17396798729896545\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "\n",
    "model = FFN()\n",
    "\n",
    "epochs = 400\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for i in range(epochs):\n",
    "    for data_batch, label_batch in train_loader:\n",
    "        output = model(data_batch)\n",
    "        loss = loss_fn(output, label_batch)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59793b92-5f23-42fe-98c4-efabddfdfaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_img(img, label=None):\n",
    "    plt.figure(figsize=(2, 2))\n",
    "    plt.imshow(img, cmap='gray_r')\n",
    "    if label is not None:\n",
    "        plt.title(f\"Label: {label}\")\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b765e2e-64e0-4b0c-8743-d9ce5a48b2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FGSM\n",
    "\n",
    "# new image = original image + perturbation scalar * neg (gradient with respect to the loss)\n",
    "\n",
    "def FGSM(img, target, scalar=3):\n",
    "    img = img.clone().view(-1).detach().requires_grad_(True)  # Input usually doesnt require grad\n",
    "    y = model(img)\n",
    "    loss = loss_fn(y, target)\n",
    "    loss.backward()\n",
    "    grad = img.grad.data\n",
    "    signed_grad = grad.sign()\n",
    "    mod_img = img + (scalar * signed_grad)\n",
    "    return mod_img.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dda52f41-ede6-41d8-afed-a3e8901d762e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (64x1 and 64x32)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m plot_img(data_tensor[\u001b[32m0\u001b[39m].view(\u001b[32m8\u001b[39m, \u001b[32m8\u001b[39m), torch.argmax(target_tensor[\u001b[32m0\u001b[39m]))\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m modified = \u001b[43mFGSM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_tensor\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_tensor\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m modified_label = torch.argmax(model(modified))\n\u001b[32m      6\u001b[39m plot_img(modified.view(\u001b[32m8\u001b[39m, \u001b[32m8\u001b[39m), modified_label)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mFGSM\u001b[39m\u001b[34m(img, target, scalar)\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mFGSM\u001b[39m(img, target, scalar=\u001b[32m3\u001b[39m):\n\u001b[32m      6\u001b[39m     img = img.clone().view(-\u001b[32m1\u001b[39m).detach().requires_grad_(\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# Input usually doesnt require grad\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     y = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m     loss = loss_fn(y, target)\n\u001b[32m      9\u001b[39m     loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/neat/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/neat/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mFFN.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m     14\u001b[39m     x = x.view(x.size(\u001b[32m0\u001b[39m), -\u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m     logits = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlinear_relu_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m logits\n\u001b[32m     18\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.softmax(logits, dim=\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/neat/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/neat/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/neat/venv/lib/python3.12/site-packages/torch/nn/modules/container.py:240\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/neat/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/neat/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/neat/venv/lib/python3.12/site-packages/torch/nn/modules/linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: mat1 and mat2 shapes cannot be multiplied (64x1 and 64x32)"
     ]
    }
   ],
   "source": [
    "plot_img(data_tensor[0].view(8, 8), torch.argmax(target_tensor[0]))\n",
    "\n",
    "modified = FGSM(data_tensor[0], target_tensor[0])\n",
    "modified_label = torch.argmax(model(modified))\n",
    "\n",
    "plot_img(modified.view(8, 8), modified_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17912d74-d1ed-4432-87d9-7b4022bf6be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.29%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, labels in train_loader:\n",
    "        data = data\n",
    "        labels = labels\n",
    "        \n",
    "        outputs = model(data)  # logits\n",
    "        predicted = torch.argmax(outputs, dim=1)  # class indices\n",
    "\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95ad5c15-c477-4afc-a6e3-9220ec638129",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, f\"../models/fnn{accuracy * 100:.2f}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02efa7e2-8eb5-45a4-95b6-0371bc768560",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
