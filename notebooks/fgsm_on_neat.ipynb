{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36d7f272-efa7-4178-b3ad-a998ed0beddc",
   "metadata": {},
   "source": [
    "FGSM on a neat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4a3e2e-0c17-4b79-bfb3-f01690c35b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10b29a290>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(\"./neat\"))\n",
    "\n",
    "from nn import *\n",
    "from mutation import *\n",
    "from speciation import *\n",
    "\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ef0358e-d2fc-4268-bb94-603ed55c71e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST\n",
    "\n",
    "ds = 'mnist'\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "class Flatten:\n",
    "    def __call__(self, x):\n",
    "        return x.view(-1)  # flatten 1x28x28 to 784\n",
    "    \n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),    # (1, 28, 28)\n",
    "    transforms.Normalize((0.1307,), (0.3081,)),  # Note: normalization expects channel dim, so do before squeeze if needed\n",
    "    Flatten()\n",
    "])\n",
    "\n",
    "# Load training and test datasets\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform)\n",
    "\n",
    "# Subset stuff\n",
    "train_size = len(train_dataset) // 100\n",
    "test_size = len(test_dataset) // 100\n",
    "\n",
    "train_subset = Subset(train_dataset, torch.randperm(len(train_dataset))[:train_size])\n",
    "test_subset = Subset(test_dataset, torch.randperm(len(test_dataset))[:test_size])\n",
    "\n",
    "train_loader = DataLoader(train_subset, batch_size=len(train_subset), shuffle=True)\n",
    "test_loader = DataLoader(test_subset, batch_size=len(test_subset), shuffle=False)\n",
    "\n",
    "# sklearn\n",
    "\n",
    "# from sklearn.datasets import load_digits\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# digits = load_digits()\n",
    "\n",
    "# data_tensor = torch.tensor(digits.data, dtype=torch.float32)\n",
    "# data_tensor = torch.tensor(digits.data / 16.0, dtype=torch.float32) # Normalize for neat\n",
    "# target_tensor = torch.tensor(digits.target, dtype=torch.long)\n",
    "\n",
    "# # 80/20 split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     data_tensor, target_tensor, test_size=0.2, random_state=42, shuffle=True\n",
    "# )\n",
    "\n",
    "# train_dataset = TensorDataset(X_train, y_train)\n",
    "# test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "# # Batch is the full size because there is no backpropogation\n",
    "# train_loader = DataLoader(train_dataset, batch_size=len(train_dataset))\n",
    "# test_loader = DataLoader(test_dataset, batch_size=len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe439ce6-9a68-421a-8e99-dcff4a69f589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.320467710494995\n",
      "Accuracy: 90.00%\n"
     ]
    }
   ],
   "source": [
    "# FFN to compare\n",
    "\n",
    "class FFN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 128, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10, bias=False),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "    \n",
    "# Training loop\n",
    "\n",
    "fnn_model = FFN()\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.Adam(fnn_model.parameters(), lr=0.001)\n",
    "optimizer = torch.optim.SGD(fnn_model.parameters(), lr=0.1)  # Higher lr to compensate for simplicity\n",
    "for i in range(epochs):\n",
    "    for data_batch, label_batch in train_loader:\n",
    "        output = fnn_model(data_batch)\n",
    "        loss = loss_fn(output, label_batch)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print(loss.item())\n",
    "\n",
    "# Evaulate\n",
    "fnn_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, labels in test_loader:\n",
    "        data = data\n",
    "        labels = labels\n",
    "        \n",
    "        outputs = fnn_model(data)  # logits\n",
    "        predicted = torch.argmax(outputs, dim=1)  # class indices\n",
    "\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a3f6ae-ba08-4f22-a03d-1e1e0a29fe93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # input shape: (batch_size, 1, 8, 8)\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, padding=1),  # output: 16 x 8 x 8\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1), # output: 32 x 8 x 8\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)  # output: 32 x 4 x 4\n",
    "        )\n",
    "        self.fc = nn.Linear(32 * 4 * 4, 10)  # final output for 10 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)        # conv layers\n",
    "        x = x.view(x.size(0), -1)     # flatten\n",
    "        logits = self.fc(x)            # linear layer to logits\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "96bf289e-eec8-4d2c-bd9e-b6de790a0083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0029288879595696926\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "\n",
    "base_m = SimpleCNN()\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(fnn_model.parameters(), lr=0.001)\n",
    "\n",
    "for i in range(epochs):\n",
    "    for data_batch, label_batch in train_loader:\n",
    "        output = fnn_model(data_batch)\n",
    "        loss = loss_fn(output, label_batch)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af748ab8-48f4-4e29-a5ab-f5b5a2d7ab3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init stuff\n",
    "\n",
    "# Hyperparameters\n",
    "input_dim = 8*8\n",
    "output_dim = 10\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load model\n",
    "neat_model = torch.load(\"./models/sklearn_digits_100pop_2000epoch_real96.67.pth\", weights_only=False)\n",
    "# fnn_model = torch.load(\"./models/fnn97.29.pth\", weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "59793b92-5f23-42fe-98c4-efabddfdfaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_img(img, label=None):\n",
    "    plt.figure(figsize=(2, 2))\n",
    "    plt.imshow(img, cmap='gray_r')\n",
    "    if label is not None:\n",
    "        plt.title(f\"Label: {label}\")\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "f9cc8454-c0b3-49ed-b1bd-ca0c02f40ac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_img(X_test[5].view(8,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "9c1a9c14-8970-4aa3-87e8-f7ae2cf8166f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_img(FGSM(fnn_model, X_test[5], y_test[5], 0.1).view(8,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8f06a5-d830-4b4a-bdcb-03a7fd4fd02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FGSM(model, img, target, scalar=.01):\n",
    "    img = img.clone().view(1, -1).requires_grad_(True)  # Input usually doesnt require grad\n",
    "    y = model(img)\n",
    "    \n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    loss = loss_fn(y, target.view(1))\n",
    "\n",
    "    loss.backward()\n",
    "    grad = img.grad.data\n",
    "    signed_grad = grad.sign()\n",
    "    mod_img = img + (scalar * signed_grad)\n",
    "    return mod_img.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1610970-c9ef-4002-91ef-089cd7cededc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PGD(model, img, target, c=False, epsilon=3, alpha=0.01, iters=20):\n",
    "    \"\"\"\n",
    "    model: neural network model\n",
    "    img: original input image (tensor)\n",
    "    target: ground truth label (tensor)\n",
    "    epsilon: max perturbation size\n",
    "    alpha: step size per iteration\n",
    "    iters: number of iterations\n",
    "    \"\"\"\n",
    "    # Make a copy of the original image to compare for projection\n",
    "    ori_img = img.clone().detach()\n",
    "    \n",
    "    # Initialize perturbed image with the original\n",
    "    perturbed_img = img.clone().detach().requires_grad_(True)\n",
    "    \n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    \n",
    "    for i in range(iters):\n",
    "        if not c:\n",
    "            outputs = model(perturbed_img.view(1, -1))\n",
    "        else:\n",
    "            outputs = model(perturbed_img.view(8, 8).unsqueeze(0).unsqueeze(0))\n",
    "\n",
    "        loss = loss_fn(outputs, target.view(1))\n",
    "        \n",
    "        model.zero_grad()\n",
    "        if perturbed_img.grad is not None:\n",
    "            perturbed_img.grad.data.zero_()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        # Take a step in direction of gradient sign\n",
    "        grad_sign = perturbed_img.grad.data.sign()\n",
    "        perturbed_img = perturbed_img + alpha * grad_sign\n",
    "        \n",
    "        # Project back into the epsilon-ball around original image\n",
    "        diff = torch.clamp(perturbed_img - ori_img, min=-epsilon, max=epsilon)\n",
    "        perturbed_img = torch.clamp(ori_img + diff, min=0, max=1).detach()  # clamp to valid image range\n",
    "        perturbed_img.requires_grad_()\n",
    "    \n",
    "    return perturbed_img.detach()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd117c0d-9d8d-49f1-a1db-436c7d6cc6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fnn Accuracy: 95.56%\n",
      "neat Accuracy: 96.67%\n"
     ]
    }
   ],
   "source": [
    "# Evaulate\n",
    "\n",
    "# Transfer attack\n",
    "\n",
    "fnn_correct = 0\n",
    "neat_correct = 0\n",
    "\n",
    "total = 0\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "\n",
    "    # data_fnn = FGSM(fnn_model, X_test[i], y_test[i]).unsqueeze(0) \n",
    "\n",
    "\n",
    "    outputs = fnn_model(X_test[i].unsqueeze(0))  # logits\n",
    "    predicted = torch.argmax(outputs, dim=1)  # class indices\n",
    "\n",
    "    fnn_correct += (predicted == y_test[i]).sum().item()\n",
    "\n",
    "    # data_neat = FGSM(neat_model, X_test[i], y_test[i]).unsqueeze(0)\n",
    "    # print(X_test[i].shape)\n",
    "    # print(data_neat.shape)\n",
    "    outputs = neat_model(X_test[i].unsqueeze(0))  # logits\n",
    "    predicted = torch.argmax(outputs, dim=1)  # class indices\n",
    "    \n",
    "    neat_correct += (predicted == y_test[i]).sum().item()\n",
    "\n",
    "    total += 1\n",
    "\n",
    "fnn_accuracy = fnn_correct / total\n",
    "neat_accuracy = neat_correct / total\n",
    "\n",
    "print(f\"fnn Accuracy: {fnn_accuracy * 100:.2f}%\")\n",
    "print(f\"neat Accuracy: {neat_accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
