{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "435996a1-f11a-4189-91fa-b227beb18c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9ef0358e-d2fc-4268-bb94-603ed55c71e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()\n",
    "\n",
    "data_tensor = torch.tensor(digits.data, dtype=torch.float32)\n",
    "target_tensor = F.one_hot(torch.tensor(digits.target), num_classes=10).float()\n",
    "\n",
    "# 80/20 split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data_tensor, target_tensor, test_size=0.2, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "# Batch is the full size because there is no backpropogation\n",
    "train_loader = DataLoader(train_dataset, batch_size=len(train_dataset))\n",
    "test_loader = DataLoader(test_dataset, batch_size=len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1176c120-0522-440f-945d-0848012d838f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEAT Classes\n",
    "\n",
    "from collections import deque, defaultdict\n",
    "import random\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, id_, input_=False, output=False):\n",
    "        self.id = id_\n",
    "        self.is_input = input_\n",
    "        self.is_output = output\n",
    "\n",
    "        self.val = None # Tensors\n",
    "        \n",
    "        self.num_incoming_connections = 0 \n",
    "        self.received = None # Keep track of nodes received before applying activation function\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "class ConnectionGene:\n",
    "    def __init__(self, in_node, out_node, innov_num, weight):\n",
    "        self.in_node = in_node # Nodes not node id\n",
    "        self.out_node = out_node\n",
    "        \n",
    "        self.innov_num = innov_num\n",
    "        \n",
    "        self.weight = weight # Weights are tensors\n",
    "        self.enable = True # If node is disabled, it CAN be reenabled\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "class NN(nn.Module):\n",
    "\n",
    "    # For assigning node ids to new nodes\n",
    "    next_node_id = 0\n",
    "    \n",
    "    # key: (in, out) \n",
    "    # value: resulting node\n",
    "    resulting_node_map = {}\n",
    "\n",
    "    # key: (in, out) \n",
    "    # value: the innov_num \n",
    "    innov_num_map = {}\n",
    "    next_innov_num = 0\n",
    "    \n",
    "    def __init__(self, input_dim, output_dim, cloned=False):\n",
    "        super(NN, self).__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        self.nodes = [] # Nodes objects in this specific NN\n",
    "        \n",
    "        self.connections_by_id = {} # Connections objects in this specific NN | in node id is key for forward lookup\n",
    "        self.connections = [] # All connections for mutating\n",
    "        \n",
    "        # Cloned models should not be inited!\n",
    "        if cloned:\n",
    "            return\n",
    "        else:\n",
    "            # When init a new model, the node nums and innov should be the same as any other new initialized model\n",
    "            # This branch is for initial population models\n",
    "            # Initalize a fully connected NN with no hidden layers\n",
    "            for i in range(input_dim):\n",
    "                if i >= NN.next_node_id:\n",
    "                    NN.next_node_id += 1\n",
    "                self.nodes.append(Node(i, True))\n",
    "    \n",
    "            for i in range(output_dim):\n",
    "                node_index = i + input_dim\n",
    "                if node_index >= NN.next_node_id:\n",
    "                    NN.next_node_id += 1\n",
    "                self.nodes.append(Node(node_index, False, True))\n",
    "\n",
    "                for in_id in range(input_dim):\n",
    "                    in_out_tuple = (in_id, node_index)\n",
    "                    \n",
    "                    if in_out_tuple not in NN.resulting_node_map:\n",
    "                        NN.resulting_node_map.update({in_out_tuple: None}) # No resulting node until it is split for the first time\n",
    "                        NN.innov_num_map.update({in_out_tuple: NN.next_innov_num}) # No resulting node until it is split for the first time\n",
    "                        NN.next_innov_num += 1\n",
    "                        \n",
    "                    innov_num = NN.innov_num_map[in_out_tuple]\n",
    "\n",
    "                    conn = ConnectionGene(self.nodes[in_id], self.nodes[node_index], innov_num, torch.randn(1))\n",
    "                    \n",
    "                    if in_id not in self.connections_by_id:\n",
    "                        self.connections_by_id[in_id] = [conn]\n",
    "                    else:\n",
    "                        self.connections_by_id[in_id].append(conn)\n",
    "\n",
    "                    self.connections.append(conn)\n",
    "                    \n",
    "                    self.nodes[node_index].num_incoming_connections += 1 # Each output starts off fully connected to input\n",
    "                            \n",
    "    def clone(self):\n",
    "        # Create a new NN instance with same input/output dims\n",
    "        new_nn = NN(self.input_dim, self.output_dim, cloned=True)\n",
    "    \n",
    "        # Deep copy nodes\n",
    "        new_nn.nodes = []\n",
    "        id_to_node = {}\n",
    "        for node in self.nodes:\n",
    "            new_node = Node(node.id, node.is_input, node.is_output)\n",
    "            new_node.num_incoming_connections = node.num_incoming_connections\n",
    "            new_nn.nodes.append(new_node)\n",
    "            id_to_node[node.id] = new_node\n",
    "    \n",
    "        # Deep copy connections\n",
    "        new_nn.connections = []\n",
    "\n",
    "        new_nn.connections_by_id = {}\n",
    "\n",
    "        for conn_list in self.connections_by_id.values():  # each value is a list of connections\n",
    "            for conn in conn_list:\n",
    "                in_node = id_to_node[conn.in_node.id]\n",
    "                out_node = id_to_node[conn.out_node.id]\n",
    "        \n",
    "                new_conn = ConnectionGene(\n",
    "                    in_node, out_node, conn.innov_num, conn.weight.clone().detach()\n",
    "                )\n",
    "                new_conn.enable = conn.enable\n",
    "\n",
    "                new_nn.connections.append(conn)\n",
    "\n",
    "                if in_node.id not in new_nn.connections_by_id:\n",
    "                    new_nn.connections_by_id[in_node.id] = [new_conn]\n",
    "                else:\n",
    "                    new_nn.connections_by_id[in_node.id].append(new_conn)\n",
    "        \n",
    "        return new_nn\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        if x.shape[1] != self.input_dim:\n",
    "            raise ValueError(\"Input dim is not correct\")\n",
    "        \n",
    "        batch_size = x.shape[0]\n",
    "\n",
    "        device = x.device\n",
    "    \n",
    "        # Create batch versions of node values and received counts and reset them to zero\n",
    "        for node in self.nodes:\n",
    "            node.val = torch.zeros(batch_size, device=device)\n",
    "            node.received = torch.zeros(batch_size, dtype=torch.int32, device=device)\n",
    "    \n",
    "        # Set input values\n",
    "        for idx in range(self.input_dim):\n",
    "            self.nodes[idx].val = x[:, idx]\n",
    "\n",
    "        # Start with nodes whose incoming connections are already satisfied AKA input nodes\n",
    "        queue = deque()\n",
    "        for node in self.nodes:\n",
    "            if node.num_incoming_connections == 0:\n",
    "                queue.append(node)\n",
    "    \n",
    "        while queue:\n",
    "            curr_node = queue.popleft()\n",
    "\n",
    "            \n",
    "            for conn in self.connections_by_id[curr_node.id]:\n",
    "                if not conn.enable:\n",
    "                    continue\n",
    "                if conn.in_node != curr_node:\n",
    "                    continue\n",
    "\n",
    "                out_node = conn.out_node\n",
    "                out_node.val += (curr_node.val * conn.weight)\n",
    "                # out_node.val += (curr_node.val)\n",
    "\n",
    "                out_node.received += 1\n",
    "    \n",
    "                # Only enqueue if all inputs are received\n",
    "                # Note: vectorized check — adds node to queue if all samples are ready\n",
    "                if (out_node.received == out_node.num_incoming_connections).all():\n",
    "                    if not out_node.is_output:\n",
    "                        out_node.val = torch.sigmoid(out_node.val)\n",
    "                    if not out_node.is_output:\n",
    "                        queue.append(out_node)\n",
    "    \n",
    "        # Collect logits from output nodes\n",
    "        output_vals = [node.val for node in self.nodes if node.is_output]\n",
    "        logits = torch.stack(output_vals, dim=1)  # shape: (batch_size, num_outputs)\n",
    "        return logits\n",
    "\n",
    "    # I think in the paper perturbation and modification are the same but i did different\n",
    "    def weight_perturbation(self, quiet=False):\n",
    "        rand_conn = random.choice(self.connections)\n",
    "        \n",
    "        mean = 0.0\n",
    "        std_dev = 0.1\n",
    "        \n",
    "        noise = torch.randn_like(rand_conn.weight) * std_dev + mean\n",
    "        rand_conn.weight += noise\n",
    "        \n",
    "        if not quiet:\n",
    "            print(f'connection {rand_conn.innov_num} (in this nn) weight perturbated to {rand_conn.weight.item():.2f}')\n",
    "        \n",
    "    def weight_modification(self, quiet=False):\n",
    "        rand_conn = random.choice(self.connections)\n",
    "\n",
    "        rand_conn.weight = torch.randn(1)\n",
    "        \n",
    "        if not quiet:\n",
    "            print(f'connection {rand_conn.innov_num} (in this nn) weight modified to {rand_conn.weight.item():.2f}')\n",
    "\n",
    "    def creates_cycle(self, source, target):\n",
    "        \"\"\"Returns True if adding an edge from `source` to `target` would create a cycle.\"\"\"\n",
    "        visited = set()\n",
    "    \n",
    "        def dfs(node):\n",
    "            if node.id in visited:\n",
    "                return False\n",
    "            if node == source:\n",
    "                return True  # Found a path back to source — would create cycle\n",
    "            visited.add(node.id)\n",
    "            for conn in self.connections:\n",
    "                if conn.enable and conn.in_node == node:\n",
    "                    if dfs(conn.out_node):\n",
    "                        return True\n",
    "            return False\n",
    "    \n",
    "        return dfs(target)\n",
    "\n",
    "    \n",
    "    def add_connection(self, quiet=False):\n",
    "        max_attempts = 1000  # prevent infinite loop\n",
    "        for _ in range(max_attempts):\n",
    "            rand_node_in = random.choice(self.nodes)\n",
    "\n",
    "            if rand_node_in.is_output:\n",
    "                continue\n",
    "        \n",
    "            rand_node_out = random.choice(self.nodes)\n",
    "            \n",
    "            if rand_node_out == rand_node_in or rand_node_out.is_input:\n",
    "                continue\n",
    "        \n",
    "            # Skip if connection already exists\n",
    "            # Basically no add connection will work in the beginning because its fully connected\n",
    "            if any(conn.in_node == rand_node_in and conn.out_node == rand_node_out for conn in self.connections):\n",
    "                continue\n",
    "\n",
    "            # Prevents acylic\n",
    "            if self.creates_cycle(rand_node_in, rand_node_out):\n",
    "                continue\n",
    "\n",
    "            in_out_tuple = (rand_node_in.id, rand_node_out.id)\n",
    "\n",
    "            if in_out_tuple not in NN.resulting_node_map:\n",
    "                NN.resulting_node_map.update({in_out_tuple: None}) # No resulting node until it is split for the first time\n",
    "                NN.innov_num_map.update({in_out_tuple: NN.next_innov_num}) # No resulting node until it is split for the first time\n",
    "                NN.next_innov_num += 1\n",
    "    \n",
    "            innov_num = NN.innov_num_map[in_out_tuple]\n",
    "    \n",
    "            conn = ConnectionGene(rand_node_in, rand_node_out, innov_num, torch.randn(1))\n",
    "            \n",
    "            if rand_node_in.id not in self.connections_by_id:\n",
    "                self.connections_by_id[rand_node_in.id ] = [conn]\n",
    "            else:\n",
    "                self.connections_by_id[rand_node_in.id ].append(conn)\n",
    "    \n",
    "            self.connections.append(conn)\n",
    "        \n",
    "            rand_node_out.num_incoming_connections += 1\n",
    "            \n",
    "            if not quiet:\n",
    "                print(f\"Connection created from node {rand_node_in.id} to node {rand_node_out.id} (innovation #{innov_num})\")\n",
    "\n",
    "            return\n",
    "            \n",
    "        if not quiet:\n",
    "            print(\"Failed to add connection after max attempts.\")\n",
    "\n",
    "    def add_node(self, quiet=False):   \n",
    "        enabled_conn_ids = [i for i, c in enumerate(self.connections) if c.enable]\n",
    "        \n",
    "        if not enabled_conn_ids:\n",
    "            if not quiet:\n",
    "                print(\"No enabled connections to split.\")\n",
    "            return\n",
    "            \n",
    "        rand_conn_id = random.choice(enabled_conn_ids)\n",
    "\n",
    "        # Splits an existing connection by adding a node\n",
    "        self.connections[rand_conn_id].enable = False\n",
    "\n",
    "        old_in_out_pair = (self.connections[rand_conn_id].in_node.id, self.connections[rand_conn_id].out_node.id)\n",
    "        # Since this connection already exists, it should be in the map. Whether it is none or not is decided\n",
    "        if NN.resulting_node_map[old_in_out_pair] is not None:\n",
    "            new_node_id = NN.resulting_node_map[old_in_out_pair]\n",
    "        else:\n",
    "            new_node_id = NN.next_node_id\n",
    "            NN.resulting_node_map[old_in_out_pair] = new_node_id\n",
    "            NN.next_node_id += 1\n",
    "\n",
    "        new_node = Node(new_node_id)\n",
    "        self.nodes.append(new_node)\n",
    "\n",
    "        in_out_tuple = (self.connections[rand_conn_id].in_node.id, new_node.id)\n",
    "\n",
    "        if in_out_tuple not in NN.resulting_node_map:\n",
    "            NN.resulting_node_map.update({in_out_tuple: None}) # No resulting node until it is split for the first time\n",
    "            NN.innov_num_map.update({in_out_tuple: NN.next_innov_num}) # No resulting node until it is split for the first time\n",
    "            NN.next_innov_num += 1\n",
    "\n",
    "        innov_num = NN.innov_num_map[in_out_tuple]\n",
    "\n",
    "        conn = ConnectionGene(self.connections[rand_conn_id].in_node, new_node, innov_num, torch.randn(1))\n",
    "        \n",
    "        if self.connections[rand_conn_id].in_node.id not in self.connections_by_id:\n",
    "            self.connections_by_id[self.connections[rand_conn_id].in_node.id ] = [conn]\n",
    "        else:\n",
    "            self.connections_by_id[self.connections[rand_conn_id].in_node.id ].append(conn)\n",
    "\n",
    "        self.connections.append(conn)\n",
    "\n",
    "        in_out_tuple = (new_node.id, self.connections[rand_conn_id].out_node.id)\n",
    "\n",
    "        if in_out_tuple not in NN.resulting_node_map:\n",
    "            NN.resulting_node_map.update({in_out_tuple: None}) # No resulting node until it is split for the first time\n",
    "            NN.innov_num_map.update({in_out_tuple: NN.next_innov_num}) # No resulting node until it is split for the first time\n",
    "            NN.next_innov_num += 1\n",
    " \n",
    "        innov_num = NN.innov_num_map[in_out_tuple]\n",
    "\n",
    "        conn = ConnectionGene(new_node, self.connections[rand_conn_id].out_node, innov_num, torch.randn(1))\n",
    "        \n",
    "        if new_node.id not in self.connections_by_id:\n",
    "            self.connections_by_id[new_node.id] = [conn]\n",
    "        else:\n",
    "            self.connections_by_id[new_node.id].append(conn)\n",
    "\n",
    "        self.connections.append(conn)\n",
    "        new_node.num_incoming_connections += 1\n",
    "  \n",
    "        if not quiet:\n",
    "            print(f'connection {rand_conn_id} split')\n",
    "\n",
    "    def toggle_connection(self, quiet=False):\n",
    "        rand_conn = random.choice(self.connections)\n",
    "\n",
    "        rand_conn.enable = not rand_conn.enable\n",
    "        \n",
    "        if not rand_conn.enable:\n",
    "            rand_conn.out_node.num_incoming_connections -= 1\n",
    "        else:\n",
    "            rand_conn.out_node.num_incoming_connections += 1\n",
    "\n",
    "        if not quiet:\n",
    "            print(f'connection {rand_conn.innov_num} (in this nn) toggled to {rand_conn.enable}')\n",
    "\n",
    "    def mutate(self, quiet=False):\n",
    "        # For this experiment i use 80 weight perturbation, 10 weight mutation, 5 add connection, 3 add node, 2 toggle\n",
    "        # Each one is chosen independently of each other\n",
    "        # Does not include crossover. That cannot be done by itself\n",
    "        new_model = self.clone()\n",
    "\n",
    "        # Do mutations on new_model\n",
    "        if random.random() < .8:\n",
    "            new_model.weight_perturbation(quiet)\n",
    "        if random.random() < .1:\n",
    "            new_model.weight_modification(quiet)\n",
    "        if random.random() < .05:\n",
    "            new_model.add_connection(quiet)\n",
    "        if random.random() < .03:\n",
    "            new_model.add_node(quiet)\n",
    "        if random.random() < .02:\n",
    "            new_model.toggle_connection(quiet)\n",
    "    \n",
    "        return new_model\n",
    "\n",
    "    def to(self, device):\n",
    "        for node in self.nodes:\n",
    "            if node.val is not None:\n",
    "                node.val = node.val.to(device)\n",
    "            if node.received is not None:\n",
    "                node.received = node.received.to(device)\n",
    "        for conn in self.connections:\n",
    "            conn.weight = conn.weight.to(device)\n",
    "        return self\n",
    "\n",
    "\n",
    "def reset_NN_class_state():\n",
    "    NN.next_node_id = 0\n",
    "    NN.resulting_node_map = {}\n",
    "    NN.innov_num_map = {}\n",
    "    NN.next_innov_num = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a08c669d-7c2d-4b73-993e-c2369ef3a35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossover(info1, info2):\n",
    "    # Equal Fitness\n",
    "    # Might not implement this rn because it doesnt happen that much\n",
    "    # if info1['loss'] == info2['loss']:\n",
    "    #     print(\"Same loss\")\n",
    "    #     return\n",
    "\n",
    "    # Find fitter model\n",
    "    fit_model, less_fit_model = (info2['model'], info1['model']) if info1['loss'] > info2['loss'] else (info1['model'], info2['model'])\n",
    "\n",
    "    # New model starts off as clone of more fit\n",
    "    new_model = fit_model.clone()\n",
    "\n",
    "    less_fit_conns = {conn.innov_num: conn for conn in less_fit_model.connections}\n",
    "\n",
    "    for i in new_model.connections:\n",
    "        if i.innov_num in less_fit_conns:\n",
    "            # Randomly decides to inherit from less_fit if there is a matching connection\n",
    "            if random.random() < 0.5:\n",
    "                other_conn = less_fit_conns[i.innov_num]\n",
    "                i.enable = other_conn.enable\n",
    "\n",
    "                # Idk this is in the paper\n",
    "                if not i.enable or not other_conn.enable:\n",
    "                    i.enable = random.random() < 0.25  \n",
    "                else:     \n",
    "                    i.weight = other_conn.weight\n",
    "\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f53ddb4b-c42d-4bb9-aab8-31764af7ab97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_compatibility(genome1, genome2, c1, c2, c3):\n",
    "    genome1_conns = {i.innov_num: i.weight for i in genome1.connections}\n",
    "    genome2_conns = {i.innov_num: i.weight for i in genome2.connections}\n",
    "\n",
    "    innovs1 = set(genome1_conns.keys())\n",
    "    innovs2 = set(genome2_conns.keys())\n",
    "\n",
    "    max_innov1 = max(innovs1) if innovs1 else 0\n",
    "    max_innov2 = max(innovs2) if innovs2 else 0\n",
    "    max_innov = max(max_innov1, max_innov2)\n",
    "\n",
    "    # Matching genes: innovation numbers in both genomes\n",
    "    matching = innovs1.intersection(innovs2)\n",
    "    # Calculate average weight difference for matching genes\n",
    "    if matching:\n",
    "        weight_diff = sum(abs(genome1_conns[i] - genome2_conns[i]) for i in matching) / len(matching)\n",
    "    else:\n",
    "        weight_diff = 0\n",
    "\n",
    "    # Excess genes: genes whose innovation number is greater than max innovation number of other genome\n",
    "    excess = 0\n",
    "    for innov in innovs1:\n",
    "        if innov > max_innov2:\n",
    "            excess += 1\n",
    "    for innov in innovs2:\n",
    "        if innov > max_innov1:\n",
    "            excess += 1\n",
    "\n",
    "    # Disjoint genes: genes that do not match and are not excess\n",
    "    disjoint = (len(innovs1 - innovs2) + len(innovs2 - innovs1)) - excess\n",
    "\n",
    "    # Normalization factor N\n",
    "    N = max(len(genome1_conns), len(genome2_conns))\n",
    "    if N < 20:\n",
    "        N = 1  # as per original NEAT paper for small genomes\n",
    "\n",
    "    delta = (c1 * excess / N) + (c2 * disjoint / N) + (c3 * weight_diff)\n",
    "        \n",
    "    return delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b493444-8475-418c-aacb-1a326cd52766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init stuff\n",
    "\n",
    "# Hyperparameters\n",
    "population_size = 300\n",
    "epochs = 200\n",
    "input_dim = 64\n",
    "output_dim = 10\n",
    "top_k = 0.1 # The percentage of genomes to keep for reproduction\n",
    "crossover_percent = 0.5\n",
    "\n",
    "# hyperparameters for measuring compatibility from https://nn.cs.utexas.edu/downloads/papers/stanley.cec02.pdf\n",
    "c1 = 1.0\n",
    "c2 = 1.0\n",
    "c3 = 3.0\n",
    "delta_thresh = 4\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Using list of lists\n",
    "# Dead species will not be kept track of. There will be no empty list\n",
    "population = []\n",
    "\n",
    "# Reset NN Class\n",
    "reset_NN_class_state()\n",
    "\n",
    "# Init first model\n",
    "new_model = {\"model\": NN(input_dim, output_dim).to(device), \"loss\": float('inf'), \"fitness\": -float('inf')}\n",
    "population.append([new_model])\n",
    "\n",
    "for _ in range(population_size - 1):\n",
    "    new_model = {\"model\": NN(input_dim, output_dim).to(device), \"loss\": float('inf'), \"fitness\": -float('inf')}\n",
    "    \n",
    "    added = False\n",
    "    for idx, species in enumerate(population):\n",
    "        delta = measure_compatibility(new_model['model'], species[0]['model'], c1, c2, c3)\n",
    "\n",
    "        if delta < delta_thresh:\n",
    "            population[idx].append(new_model)\n",
    "            added = True\n",
    "            break\n",
    "    if not added:\n",
    "        # New species created\n",
    "        population.append([new_model])\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27876d56-916c-4695-b0b7-9cb94b94bd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Training\" loop\n",
    "\n",
    "import math\n",
    "import time\n",
    "\n",
    "for epoch in range(epochs):  \n",
    "    for species in population:\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for model_info in species:\n",
    "                model_info[\"model\"] = model_info[\"model\"].to(device)\n",
    "                model = model_info[\"model\"]\n",
    "                total_loss = 0.0\n",
    "                total_samples = 0\n",
    "    \n",
    "                for data_batch, label_batch in train_loader:\n",
    "                    data_batch = data_batch.to(device)\n",
    "                    label_batch = label_batch.to(device)\n",
    "\n",
    "                    output = model(data_batch)\n",
    "                    loss = loss_fn(output, label_batch)\n",
    "                    total_loss += loss.item() * data_batch.size(0)\n",
    "                    total_samples += data_batch.size(0)\n",
    "                \n",
    "                model_info[\"loss\"] = total_loss / total_samples\n",
    "\n",
    "    flattened_population = []\n",
    "\n",
    "    for species in population:\n",
    "        for genome in species:\n",
    "            flattened_population.append(genome)\n",
    "            \n",
    "    ranked_models = sorted([model_info for model_info in flattened_population], key=lambda x: x[\"loss\"])\n",
    "    lowest_loss = ranked_models[0]['loss']\n",
    "\n",
    "    # Fitness sharing\n",
    "    for species in population:\n",
    "        species_size = len(species)\n",
    "        for genome in species:\n",
    "            raw_fitness = 1 / (1 + genome['loss'])\n",
    "            genome['fitness'] = raw_fitness / species_size\n",
    "\n",
    "    # Last epoch do not make new models\n",
    "    if epoch == epochs - 1:\n",
    "        break\n",
    "\n",
    "    # This is just a list not a list of lists\n",
    "    new_population = []\n",
    "\n",
    "    for species in population:\n",
    "        offspring = []\n",
    "\n",
    "        ranked_models = sorted([model_info for model_info in species], key=lambda x: x[\"fitness\"], reverse=True)\n",
    "        parents = [model_info for model_info in ranked_models[:math.ceil(top_k * len(ranked_models))]]\n",
    "\n",
    "        for i in range(math.ceil(crossover_percent * len(ranked_models))):\n",
    "            p1 = random.choice(parents)\n",
    "            p2 = random.choice(parents)\n",
    "            child = crossover(p1, p2)\n",
    "            offspring.append({\"model\": child.to(device), \"loss\": float('inf'), \"fitness\": -float('inf')})\n",
    "    \n",
    "        while len(offspring) != len(ranked_models):\n",
    "            offspring.append({\"model\": random.choice(parents)['model'].mutate(True).to(device), \"loss\": float('inf'), \"fitness\": -float('inf')})\n",
    "            \n",
    "        new_population.extend(offspring)\n",
    "\n",
    "    # Redivide into species\n",
    "    new_population_divided = []\n",
    "\n",
    "    for model in new_population:    \n",
    "        # First model\n",
    "        if len(new_population_divided) == 0:\n",
    "            new_population_divided.append([model])\n",
    "        else:\n",
    "            added = False\n",
    "            for idx, species in enumerate(new_population_divided):\n",
    "                delta = measure_compatibility(model['model'], species[0]['model'], c1, c2, c3)\n",
    "\n",
    "                if delta < delta_thresh:\n",
    "                    new_population_divided[idx].append(model)\n",
    "                    added = True\n",
    "                    break\n",
    "            if not added:\n",
    "                # New species created\n",
    "                new_population_divided.append([model])\n",
    "                    \n",
    "    population = new_population_divided\n",
    "\n",
    "    # To keep track of the num of species per epoch\n",
    "    print(f\"epoch: {epoch}\")\n",
    "    print(f\"top model loss: {lowest_loss:.2f}\")\n",
    "    print(len(population))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "b6eebbea-a693-4f2b-8211-94da81cc56be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.39%\n"
     ]
    }
   ],
   "source": [
    "model = ranked_models[0]['model'].to(device)\n",
    "\n",
    "# Evaulate\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, one_hot_labels in test_loader:\n",
    "        data = data.to(device)\n",
    "        one_hot_labels = one_hot_labels.to(device)\n",
    "        \n",
    "        outputs = model(data)  # logits\n",
    "        predicted = torch.argmax(outputs, dim=1)  # class indices\n",
    "        true_labels = torch.argmax(one_hot_labels, dim=1)  # class indices from one-hot\n",
    "\n",
    "        correct += (predicted == true_labels).sum().item()\n",
    "        total += true_labels.size(0)\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b95e99-eb95-4baf-8c9d-d2e6c08198e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neat",
   "language": "python",
   "name": "neat"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
